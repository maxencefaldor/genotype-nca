{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Cellular Automatas for growing neural structures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import requests\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from flax import linen as nn\n",
    "from flax.core.frozen_dict import freeze, unfreeze\n",
    "import optax\n",
    "\n",
    "from clu import metrics\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "from flax import struct                # Flax dataclasses\n",
    "import optax                           # Common loss functions and optimizers\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params / Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Cellular Automata Parameters\n",
    "CHANNEL_N = 16  # Number of CA state channels\n",
    "TARGET_PADDING = 16  # Number of pixels used to pad the target image border\n",
    "TARGET_SIZE = 40\n",
    "BATCH_SIZE = 256\n",
    "POOL_SIZE = 1024\n",
    "CELL_FIRE_RATE = 0.5\n",
    "N_STEPS = 10\n",
    "TARGET_EMOJI = \"ðŸ¦Ž\"  # @param {type:\"string\"}\n",
    "\n",
    "EXPERIMENT_TYPE = \"Regenerating\"  # @param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
    "EXPERIMENT_MAP = {\"Growing\": 0, \"Persistent\": 1, \"Regenerating\": 2}\n",
    "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
    "\n",
    "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
    "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(url, max_size=TARGET_SIZE):\n",
    "    r = requests.get(url)\n",
    "    img = PIL.Image.open(io.BytesIO(r.content))\n",
    "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
    "    img = np.float32(img) / 255.0\n",
    "    # premultiply RGB by Alpha\n",
    "    img[..., :3] *= img[..., 3:]\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_emoji(emoji):\n",
    "    code = hex(ord(emoji))[2:].lower()\n",
    "    url = (\n",
    "        \"https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true\"\n",
    "        % code\n",
    "    )\n",
    "    return load_image(url)\n",
    "\n",
    "\n",
    "def to_rgba(x):\n",
    "    return x[..., :4]\n",
    "\n",
    "\n",
    "def to_alpha(x):\n",
    "    return x[..., 3:4].clip(0.0, 1.0)\n",
    "\n",
    "\n",
    "def to_rgb(x):\n",
    "    # assume rgb premultiplied by alpha\n",
    "    rgb, a = x[..., :3], to_alpha(x)\n",
    "    return 1.0 - a + rgb\n",
    "\n",
    "\n",
    "def get_living_mask(x):\n",
    "    return x[:, :, :, 3:4] > 0.1\n",
    "    # return nn.max_pool(alpha, 3, [1, 1, 1, 1], 'SAME') > 0.1\n",
    "\n",
    "\n",
    "def make_seed(size, n=1):\n",
    "    x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
    "    x[:, size // 2, size // 2, 3:] = 1.0\n",
    "    return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perception(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.Conv(\n",
    "            features=3,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=\"SAME\",\n",
    "            use_bias=False,\n",
    "        )(x)\n",
    "\n",
    "\n",
    "class Update(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.Sequential(\n",
    "            [\n",
    "                nn.Dense(features=128, use_bias=True),\n",
    "                nn.relu,\n",
    "                nn.Dense(features=CHANNEL_N, use_bias=True),\n",
    "            ]\n",
    "        )(x)\n",
    "\n",
    "\n",
    "class CAModel(nn.Module):\n",
    "\n",
    "    channel_n = CHANNEL_N\n",
    "    fire_rate = CELL_FIRE_RATE\n",
    "    angle = 0.0\n",
    "\n",
    "    def setup(self):\n",
    "        self.pmodel = Perception()\n",
    "        self.dmodel = Update()\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, rng_key, fire_rate=None, step_size=1.0):\n",
    "\n",
    "        pre_life_mask = get_living_mask(x)\n",
    "\n",
    "        y = self.pmodel(x)\n",
    "        dx = self.dmodel(y) * step_size\n",
    "        if fire_rate is None:\n",
    "            fire_rate = self.fire_rate\n",
    "\n",
    "        update_mask = (\n",
    "            jax.random.uniform(rng_key, shape=x[:, :, :, :1].shape) <= fire_rate\n",
    "        )\n",
    "        x += dx * update_mask.astype(jnp.float32)\n",
    "\n",
    "        post_life_mask = get_living_mask(x)\n",
    "        life_mask = pre_life_mask & post_life_mask\n",
    "        return x * life_mask.astype(jnp.float32)\n",
    "\n",
    "\n",
    "def get_kernel(angle=0, channel_n=CHANNEL_N):\n",
    "    identify = np.float32([0, 1, 0])\n",
    "    identify = np.outer(identify, identify)\n",
    "    dx = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
    "    dy = dx.T\n",
    "    c, s = np.cos(angle), jnp.sin(angle)\n",
    "    kernel = np.stack([identify, c * dx - s * dy, s * dx + c * dy], -1)[:, :, None, :]\n",
    "    kernel = np.repeat(kernel, channel_n, axis=2)\n",
    "    kernel = jnp.array(kernel).astype(jnp.float32)\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def set_params(self, params, angle=0, channel_n=CHANNEL_N):\n",
    "    kernel = get_kernel(angle, channel_n)\n",
    "    params = unfreeze(params)\n",
    "    params[\"pmodel\"]['Conv_0'][\"kernel\"] = kernel\n",
    "    params = freeze(params)\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "  loss: metrics.Average.from_output('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "  metrics: Metrics\n",
    "\n",
    "def create_train_state(module, size, rng, learning_rate, momentum, angle=0.0):\n",
    "  \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "  rng1, rng2 = jax.random.split(rng) \n",
    "  params = module.init(rng1, make_seed(size), rng2)['params'] # initialize parameters by passing a template image\n",
    "  params = set_params(module, params, angle)\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return TrainState.create(\n",
    "      apply_fn=module.apply, params=params, tx=tx,\n",
    "      metrics=Metrics.empty())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@jax.jit\n",
    "def train_step(state, batch, n_steps):\n",
    "  grid, target, rng_key = batch\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  def loss_fn(params):\n",
    "    out = grid\n",
    "    for _ in range(n_steps):\n",
    "      out = state.apply_fn({'params': params}, x=grid, rng_key=rng_key)\n",
    "    out = state.apply_fn({'params': state.params}, x=grid, rng_key=rng_key)\n",
    "    loss = ((target - out[..., :4]) ** 2).mean()\n",
    "    return loss\n",
    "  grad_fn = jax.grad(loss_fn, allow_int=True)\n",
    "  grads = grad_fn(state.params)\n",
    "  print(grads)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_model = CAModel()\n",
    "init_rng = jax.random.PRNGKey(0)\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "state = create_train_state(ca_model, TARGET_SIZE, init_rng, learning_rate, momentum)\n",
    "del init_rng  # Must not be used anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "[ax.imshow(k) for k, ax in zip(state.params['pmodel']['Conv_0']['kernel'][:, :, 0, :].T, axs)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414971342b5d4e0dac18bfe86a2947d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenDict({\n",
      "    dmodel: {\n",
      "        Dense_0: {\n",
      "            bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                   0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                   0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                   0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                   0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                   0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                   0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                   0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
      "            kernel: Array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "                   [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "                   [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "                    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],      dtype=float32),\n",
      "        },\n",
      "        Dense_1: {\n",
      "            bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float32),\n",
      "            kernel: Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "                   [0., 0., 0., ..., 0., 0., 0.],\n",
      "                   [0., 0., 0., ..., 0., 0., 0.],\n",
      "                   ...,\n",
      "                   [0., 0., 0., ..., 0., 0., 0.],\n",
      "                   [0., 0., 0., ..., 0., 0., 0.],\n",
      "                   [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
      "        },\n",
      "    },\n",
      "    pmodel: {\n",
      "        Conv_0: {\n",
      "            kernel: Array([[[[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]],\n",
      "            \n",
      "                    [[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]],\n",
      "            \n",
      "                    [[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]]],\n",
      "            \n",
      "            \n",
      "                   [[[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]],\n",
      "            \n",
      "                    [[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]],\n",
      "            \n",
      "                    [[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]]],\n",
      "            \n",
      "            \n",
      "                   [[[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]],\n",
      "            \n",
      "                    [[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]],\n",
      "            \n",
      "                    [[0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.],\n",
      "                     [0., 0., 0.]]]], dtype=float32),\n",
      "        },\n",
      "    },\n",
      "})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones_like(x)[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :\u001b[39m4\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[39m# Run optimization steps over training batches and compute batch metrics\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m state \u001b[39m=\u001b[39m train_step(state, (x, target, subkey), N_STEPS)\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(state, batch, n_steps)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[39mreturn\u001b[39;00m loss\n\u001b[1;32m     12\u001b[0m grad_fn \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mgrad(loss_fn, allow_int\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m grads \u001b[39m=\u001b[39m grad_fn(state\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(grads)\n\u001b[1;32m     15\u001b[0m state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_gradients(grads\u001b[39m=\u001b[39mgrads)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/api.py:646\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39m@wraps\u001b[39m(fun, docstr\u001b[39m=\u001b[39mdocstr, argnums\u001b[39m=\u001b[39margnums)\n\u001b[1;32m    644\u001b[0m \u001b[39m@api_boundary\u001b[39m\n\u001b[1;32m    645\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrad_f\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 646\u001b[0m   _, g \u001b[39m=\u001b[39m value_and_grad_f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    647\u001b[0m   \u001b[39mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/api.py:722\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    721\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 722\u001b[0m   ans, vjp_py \u001b[39m=\u001b[39m _vjp(f_partial, \u001b[39m*\u001b[39mdyn_args, reduce_axes\u001b[39m=\u001b[39mreduce_axes)\n\u001b[1;32m    723\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m   ans, vjp_py, aux \u001b[39m=\u001b[39m _vjp(\n\u001b[1;32m    725\u001b[0m       f_partial, \u001b[39m*\u001b[39mdyn_args, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_axes\u001b[39m=\u001b[39mreduce_axes)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/api.py:2177\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2176\u001b[0m   flat_fun, out_tree \u001b[39m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2177\u001b[0m   out_primal, out_vjp \u001b[39m=\u001b[39m ad\u001b[39m.\u001b[39mvjp(\n\u001b[1;32m   2178\u001b[0m       flat_fun, primals_flat, reduce_axes\u001b[39m=\u001b[39mreduce_axes)\n\u001b[1;32m   2179\u001b[0m   out_tree \u001b[39m=\u001b[39m out_tree()\n\u001b[1;32m   2180\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:139\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvjp\u001b[39m(traceable, primals, has_aux\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, reduce_axes\u001b[39m=\u001b[39m()):\n\u001b[1;32m    138\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 139\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[39m=\u001b[39m linearize(traceable, \u001b[39m*\u001b[39mprimals)\n\u001b[1;32m    140\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[39m=\u001b[39m linearize(traceable, \u001b[39m*\u001b[39mprimals, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:128\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m _, in_tree \u001b[39m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    127\u001b[0m jvpfun_flat, out_tree \u001b[39m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 128\u001b[0m jaxpr, out_pvals, consts \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39mtrace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n\u001b[1;32m    129\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[39m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    130\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(out_primal_pval\u001b[39m.\u001b[39mis_known() \u001b[39mfor\u001b[39;00m out_primal_pval \u001b[39min\u001b[39;00m out_primals_pvals)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py:777\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[39mwith\u001b[39;00m core\u001b[39m.\u001b[39mnew_main(JaxprTrace, name_stack\u001b[39m=\u001b[39mcurrent_name_stack) \u001b[39mas\u001b[39;00m main:\n\u001b[1;32m    776\u001b[0m   fun \u001b[39m=\u001b[39m trace_to_subjaxpr_nounits(fun, main, instantiate)\n\u001b[0;32m--> 777\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[39m=\u001b[39m fun\u001b[39m.\u001b[39mcall_wrapped(pvals)\n\u001b[1;32m    778\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m env\n\u001b[1;32m    779\u001b[0m   \u001b[39mdel\u001b[39;00m main, fun, env\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/linear_util.py:188\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m    189\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    191\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    192\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    193\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    194\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mtrain_step.<locals>.loss_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      6\u001b[0m out \u001b[39m=\u001b[39m grid\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_steps):\n\u001b[0;32m----> 8\u001b[0m   out \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_fn({\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: params}, x\u001b[39m=\u001b[39mgrid, rng_key\u001b[39m=\u001b[39mrng_key)\n\u001b[1;32m      9\u001b[0m out \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_fn({\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: state\u001b[39m.\u001b[39mparams}, x\u001b[39m=\u001b[39mgrid, rng_key\u001b[39m=\u001b[39mrng_key)\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m ((target \u001b[39m-\u001b[39m out[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :\u001b[39m4\u001b[39m]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean()\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:1489\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, variables, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m   method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m\n\u001b[1;32m   1488\u001b[0m method \u001b[39m=\u001b[39m _get_unbound_fn(method)\n\u001b[0;32m-> 1489\u001b[0m \u001b[39mreturn\u001b[39;00m apply(\n\u001b[1;32m   1490\u001b[0m     method, \u001b[39mself\u001b[39m,\n\u001b[1;32m   1491\u001b[0m     mutable\u001b[39m=\u001b[39mmutable,\n\u001b[1;32m   1492\u001b[0m     capture_intermediates\u001b[39m=\u001b[39mcapture_intermediates,\n\u001b[1;32m   1493\u001b[0m )(variables, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, rngs\u001b[39m=\u001b[39mrngs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/core/scope.py:933\u001b[0m, in \u001b[0;36mapply.<locals>.wrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mApplyScopeInvalidVariablesStructureError(variables)\n\u001b[1;32m    931\u001b[0m \u001b[39mwith\u001b[39;00m bind(variables, rngs\u001b[39m=\u001b[39mrngs, mutable\u001b[39m=\u001b[39mmutable,\n\u001b[1;32m    932\u001b[0m           flags\u001b[39m=\u001b[39mflags)\u001b[39m.\u001b[39mtemporary() \u001b[39mas\u001b[39;00m root:\n\u001b[0;32m--> 933\u001b[0m   y \u001b[39m=\u001b[39m fn(root, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m mutable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m   \u001b[39mreturn\u001b[39;00m y, root\u001b[39m.\u001b[39mmutable_variables()\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:2060\u001b[0m, in \u001b[0;36mapply.<locals>.scope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2058\u001b[0m _context\u001b[39m.\u001b[39mcapture_stack\u001b[39m.\u001b[39mappend(capture_intermediates)\n\u001b[1;32m   2059\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2060\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(module\u001b[39m.\u001b[39mclone(parent\u001b[39m=\u001b[39mscope), \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2061\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2062\u001b[0m   _context\u001b[39m.\u001b[39mcapture_stack\u001b[39m.\u001b[39mpop()\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:432\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    431\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 432\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:864\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    863\u001b[0m   \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[39mself\u001b[39m, fun)):\n\u001b[0;32m--> 864\u001b[0m     y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mCAModel.__call__\u001b[0;34m(self, x, rng_key, fire_rate, step_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m pre_life_mask \u001b[39m=\u001b[39m get_living_mask(x)\n\u001b[1;32m     40\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpmodel(x)\n\u001b[0;32m---> 41\u001b[0m dx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdmodel(y) \u001b[39m*\u001b[39m step_size\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m fire_rate \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     fire_rate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfire_rate\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:432\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    431\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 432\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:864\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    863\u001b[0m   \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[39mself\u001b[39m, fun)):\n\u001b[0;32m--> 864\u001b[0m     y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mUpdate.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m@nn\u001b[39m\u001b[39m.\u001b[39mcompact\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mreturn\u001b[39;00m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     17\u001b[0m         [\n\u001b[1;32m     18\u001b[0m             nn\u001b[39m.\u001b[39mDense(features\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, use_bias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     19\u001b[0m             nn\u001b[39m.\u001b[39mrelu,\n\u001b[1;32m     20\u001b[0m             nn\u001b[39m.\u001b[39mDense(features\u001b[39m=\u001b[39mCHANNEL_N, use_bias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     21\u001b[0m         ]\n\u001b[1;32m     22\u001b[0m     )(x)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:432\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    431\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 432\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:864\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    863\u001b[0m   \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[39mself\u001b[39m, fun)):\n\u001b[0;32m--> 864\u001b[0m     y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/combinators.py:77\u001b[0m, in \u001b[0;36mSequential.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m     75\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEmpty Sequential module \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m     79\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:432\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    431\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 432\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/module.py:864\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    863\u001b[0m   \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[39mself\u001b[39m, fun)):\n\u001b[0;32m--> 864\u001b[0m     y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/flax/linen/linear.py:206\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    204\u001b[0m   bias \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    205\u001b[0m inputs, kernel, bias \u001b[39m=\u001b[39m promote_dtype(inputs, kernel, bias, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 206\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdot_general(\n\u001b[1;32m    207\u001b[0m     inputs,\n\u001b[1;32m    208\u001b[0m     kernel,\n\u001b[1;32m    209\u001b[0m     (((inputs\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,), (\u001b[39m0\u001b[39m,)), ((), ())),\n\u001b[1;32m    210\u001b[0m     precision\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision,\n\u001b[1;32m    211\u001b[0m )\n\u001b[1;32m    212\u001b[0m \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m   y \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mreshape(bias, (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m (y\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,))\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/lax/lax.py:748\u001b[0m, in \u001b[0;36mdot_general\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m    743\u001b[0m bdims \u001b[39m=\u001b[39m (api_util\u001b[39m.\u001b[39m_ensure_index_tuple(lhs_batch),\n\u001b[1;32m    744\u001b[0m          api_util\u001b[39m.\u001b[39m_ensure_index_tuple(rhs_batch))\n\u001b[1;32m    745\u001b[0m preferred_element_type \u001b[39m=\u001b[39m (\n\u001b[1;32m    746\u001b[0m     \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m preferred_element_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m\n\u001b[1;32m    747\u001b[0m     dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(np\u001b[39m.\u001b[39mdtype(preferred_element_type)))\n\u001b[0;32m--> 748\u001b[0m \u001b[39mreturn\u001b[39;00m dot_general_p\u001b[39m.\u001b[39mbind(lhs, rhs,\n\u001b[1;32m    749\u001b[0m                           dimension_numbers\u001b[39m=\u001b[39m(cdims, bdims),\n\u001b[1;32m    750\u001b[0m                           precision\u001b[39m=\u001b[39mcanonicalize_precision(precision),\n\u001b[1;32m    751\u001b[0m                           preferred_element_type\u001b[39m=\u001b[39mpreferred_element_type)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/core.py:380\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    378\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    379\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 380\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/core.py:383\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 383\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mprocess_primitive(\u001b[39mself\u001b[39m, \u001b[39mmap\u001b[39m(trace\u001b[39m.\u001b[39mfull_raise, args), params)\n\u001b[1;32m    384\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:315\u001b[0m, in \u001b[0;36mJVPTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    313\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDifferentiation rule for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mprimitive\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not implemented\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(msg)\n\u001b[0;32m--> 315\u001b[0m primal_out, tangent_out \u001b[39m=\u001b[39m jvp(primals_in, tangents_in, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m primitive\u001b[39m.\u001b[39mmultiple_results:\n\u001b[1;32m    317\u001b[0m   \u001b[39mreturn\u001b[39;00m [JVPTracer(\u001b[39mself\u001b[39m, x, t) \u001b[39mfor\u001b[39;00m x, t \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(primal_out, tangent_out)]\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:530\u001b[0m, in \u001b[0;36mstandard_jvp\u001b[0;34m(jvprules, primitive, primals, tangents, **params)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstandard_jvp\u001b[39m(jvprules, primitive, primals, tangents, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m--> 530\u001b[0m   val_out \u001b[39m=\u001b[39m primitive\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39mprimals, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    531\u001b[0m   tangents_out \u001b[39m=\u001b[39m [rule(t, \u001b[39m*\u001b[39mprimals, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams) \u001b[39mfor\u001b[39;00m rule, t \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(jvprules, tangents)\n\u001b[1;32m    532\u001b[0m                   \u001b[39mif\u001b[39;00m rule \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(t) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Zero]\n\u001b[1;32m    533\u001b[0m   \u001b[39mreturn\u001b[39;00m val_out, functools\u001b[39m.\u001b[39mreduce(add_tangents, tangents_out, Zero\u001b[39m.\u001b[39mfrom_value(val_out))\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/core.py:380\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    378\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    379\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 380\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/core.py:383\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 383\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mprocess_primitive(\u001b[39mself\u001b[39m, \u001b[39mmap\u001b[39m(trace\u001b[39m.\u001b[39mfull_raise, args), params)\n\u001b[1;32m    384\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/core.py:790\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 790\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39mimpl(\u001b[39m*\u001b[39mtracers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/dispatch.py:143\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    139\u001b[0m   msg \u001b[39m=\u001b[39m pjit\u001b[39m.\u001b[39m_device_assignment_mismatch_error(\n\u001b[1;32m    140\u001b[0m       prim\u001b[39m.\u001b[39mname, fails, args, \u001b[39m'\u001b[39m\u001b[39mjit\u001b[39m\u001b[39m'\u001b[39m, arg_names)\n\u001b[1;32m    141\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fun(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/dispatch.py:226\u001b[0m, in \u001b[0;36mxla_primitive_callable.<locals>.<lambda>\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    222\u001b[0m compiled \u001b[39m=\u001b[39m _xla_callable_uncached(\n\u001b[1;32m    223\u001b[0m     lu\u001b[39m.\u001b[39mwrap_init(prim_fun), prim\u001b[39m.\u001b[39mname, donated_invars, \u001b[39mFalse\u001b[39;00m, in_avals,\n\u001b[1;32m    224\u001b[0m     orig_in_shardings)\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prim\u001b[39m.\u001b[39mmultiple_results:\n\u001b[0;32m--> 226\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: compiled(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m   \u001b[39mreturn\u001b[39;00m compiled\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1346\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1341\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_token_bufs(\n\u001b[1;32m   1342\u001b[0m       results\u001b[39m.\u001b[39mdisassemble_prefix_into_single_device_arrays(\n\u001b[1;32m   1343\u001b[0m           \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mordered_effects)),\n\u001b[1;32m   1344\u001b[0m       results\u001b[39m.\u001b[39mconsume_token())\n\u001b[1;32m   1345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1346\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxla_executable\u001b[39m.\u001b[39mexecute_sharded(input_bufs)\n\u001b[1;32m   1347\u001b[0m \u001b[39mif\u001b[39;00m dispatch\u001b[39m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1348\u001b[0m   out_arrays \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rng_key = jax.random.PRNGKey(0)\n",
    "for batch in tqdm(range(10)):\n",
    "  rng_key, subkey = jax.random.split(rng_key)\n",
    "  x = make_seed(TARGET_SIZE, BATCH_SIZE)\n",
    "  target = np.ones_like(x)[..., :4]\n",
    "  # Run optimization steps over training batches and compute batch metrics\n",
    "  state = train_step(state, (x, target, subkey), N_STEPS) # get updated train state (which contains the updated parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdf14ab18d0>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = make_seed(TARGET_SIZE, BATCH_SIZE)\n",
    "rng_key, subkey = jax.random.split(rng_key)\n",
    "out = x.copy()\n",
    "for _ in range(10) : \n",
    "    out = ca_model.apply({'params': state.params}, x=out, rng_key=subkey)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(to_rgb(x[0, ..., :4]))\n",
    "axs[1].imshow(to_rgb(out[0, ..., :4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.00370619, dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0, ..., :4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "community",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
