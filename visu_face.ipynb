{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax.training.train_state import TrainState\n",
    "import optax\n",
    "import pandas as pd\n",
    "\n",
    "from common.cell import to_rgb, to_rgba, make_ellipse_mask\n",
    "from common.pool import Pool\n",
    "from common.nca import NCA\n",
    "from common.vae import vae_dict\n",
    "from common.utils import load_face, jnp2pil, visualize_nca, load_params\n",
    "\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "run_path = Path(\"/project/output/face/2023-08-18_095035_765053\")\n",
    "config = OmegaConf.load(run_path / \".hydra\" / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.exp.dataset_size = 1000\n",
    "config.exp.n_perceive_free = 6\n",
    "config.exp.update_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 999/1000 [00:02<00:00, 334.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in VAE:  34510979\n",
      "Number of parameters in NCA:  100936\n"
     ]
    }
   ],
   "source": [
    "# Init a random key\n",
    "random_key = jax.random.PRNGKey(config.seed)\n",
    "\n",
    "# Load VAE\n",
    "vae_dir = Path(config.exp.vae_dir)\n",
    "vae_config = OmegaConf.load(vae_dir / \".hydra\" / \"config.yaml\")\n",
    "\n",
    "# Load list_attr_celeba.txt file into a pandas DataFrame\n",
    "df_attr_celeba = pd.read_csv(vae_config.exp.attr_dir, sep=\"\\s+\", skiprows=1)\n",
    "df_attr_celeba.replace(to_replace=-1, value=0, inplace=True) # replace -1 by 0\n",
    "\n",
    "# Load list_landmarks_align_celeba.txt file into a pandas DataFrame\n",
    "df_landmarks_align_celeba = pd.read_csv(vae_config.exp.landmarks_dir, sep=\"\\s+\", skiprows=1)\n",
    "\n",
    "# Crop images from (218, 178) to (178, 178)\n",
    "df_landmarks_align_celeba[\"lefteye_y\"] = df_landmarks_align_celeba[\"lefteye_y\"] - (218 - 178) / 2\n",
    "df_landmarks_align_celeba[\"righteye_y\"] = df_landmarks_align_celeba[\"righteye_y\"] - (218 - 178) / 2\n",
    "df_landmarks_align_celeba[\"nose_y\"] = df_landmarks_align_celeba[\"nose_y\"] - (218 - 178) / 2\n",
    "df_landmarks_align_celeba[\"leftmouth_y\"] = df_landmarks_align_celeba[\"leftmouth_y\"] - (218 - 178) / 2\n",
    "df_landmarks_align_celeba[\"rightmouth_y\"] = df_landmarks_align_celeba[\"rightmouth_y\"] - (218 - 178) / 2\n",
    "\n",
    "# Resize images from (178, 178) to face_shape\n",
    "df_landmarks_align_celeba /= 178/vae_config.exp.face_shape[0]\n",
    "\n",
    "# Dataset\n",
    "height, width = vae_config.exp.face_shape[:2]\n",
    "if config.exp.dataset_size == -1:\n",
    "    dataset_size = df_landmarks_align_celeba.shape[0]\n",
    "else:\n",
    "    dataset_size = config.exp.dataset_size\n",
    "\n",
    "if vae_config.exp.grayscale:\n",
    "    dataset_phenotypes_target = np.zeros((dataset_size, *vae_config.exp.face_shape, 1))\n",
    "else:\n",
    "    dataset_phenotypes_target = np.zeros((dataset_size, *vae_config.exp.face_shape, 3))\n",
    "\n",
    "mask = np.zeros((dataset_size, height, width, 1,))\n",
    "for i, (index, row,) in tqdm(enumerate(df_landmarks_align_celeba.iterrows()), total=dataset_size):\n",
    "    dataset_phenotypes_target[i] = load_face(vae_config.exp.dataset_dir + index, vae_config.exp.face_shape, vae_config.exp.grayscale)\n",
    "    center = (row[\"lefteye_x\"] + row[\"righteye_x\"]) / 2, (row[\"lefteye_y\"] + row[\"righteye_y\"]) / 2\n",
    "    mask[i, ..., 0] = make_ellipse_mask(center, width, height, 0.7*width/2, 0.9*height/2)\n",
    "    if i == dataset_size-1:\n",
    "        break\n",
    "dataset_phenotypes_target = dataset_phenotypes_target * mask\n",
    "\n",
    "# VAE\n",
    "vae = vae_dict[vae_config.exp.vae_index](img_shape=dataset_phenotypes_target[0].shape, latent_size=vae_config.exp.latent_size)\n",
    "random_key, random_subkey_1, random_subkey_2 = jax.random.split(random_key, 3)\n",
    "vae_params = vae.init(random_subkey_1, random_subkey_2, dataset_phenotypes_target[0])\n",
    "vae_params = load_params(vae_params, vae_dir / \"vae.pickle\")\n",
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(vae_params))\n",
    "print(\"Number of parameters in VAE: \", param_count)\n",
    "\n",
    "# Cell states\n",
    "if vae_config.exp.grayscale:\n",
    "    phenotype_size = 1\n",
    "    cell_state_size = phenotype_size + 1 + config.exp.hidden_size\n",
    "else:\n",
    "    phenotype_size = 3\n",
    "    cell_state_size = phenotype_size + 1 + config.exp.hidden_size\n",
    "\n",
    "@jax.jit\n",
    "def phenotype_to_genotype(random_key, phenotype_target):\n",
    "    z, _, _ = vae.apply(vae_params, random_key, phenotype_target, method=vae.encode)\n",
    "    return z\n",
    "\n",
    "@jax.jit\n",
    "def init_cell_state():\n",
    "    cell_state = jnp.zeros((phenotype_size+1+config.exp.hidden_size,))  # init cell_state\n",
    "    cell_state = cell_state.at[phenotype_size:].set(1.0)  # set alpha and hidden channels to 1.0\n",
    "    return cell_state\n",
    "\n",
    "@jax.jit\n",
    "def init_cells_state(_):\n",
    "    cell_state = init_cell_state()\n",
    "    cells_state = jnp.zeros((height, width, cell_state_size,))\n",
    "    return cells_state.at[height//2, width//2].set(cell_state)\n",
    "\n",
    "def phenotype_to_genotype_scan(carry, x):\n",
    "    random_key, phenotype_target = x\n",
    "    z = phenotype_to_genotype(random_key, phenotype_target)\n",
    "    return (), z\n",
    "\n",
    "random_keys = jax.random.split(random_key, 1+dataset_phenotypes_target.shape[0])\n",
    "random_key, random_keys = random_keys[-1], random_keys[:-1]\n",
    "_, dataset_genotypes_target = jax.lax.scan(\n",
    "    phenotype_to_genotype_scan,\n",
    "    (),\n",
    "    (random_keys, dataset_phenotypes_target),\n",
    "    length=dataset_phenotypes_target.shape[0])\n",
    "\n",
    "# Trainset - Testset phenotypes\n",
    "dataset_phenotypes_target = np.concatenate([dataset_phenotypes_target, mask], axis=-1)\n",
    "trainset_phenotypes_target = dataset_phenotypes_target[:int(0.9 * len(dataset_phenotypes_target))]\n",
    "testset_phenotypes_target = dataset_phenotypes_target[int(0.9 * len(dataset_phenotypes_target)):]\n",
    "\n",
    "# Trainset - Testset genotypes\n",
    "trainset_genotypes_target = dataset_genotypes_target[:int(0.9 * len(dataset_genotypes_target))]\n",
    "testset_genotypes_target = dataset_genotypes_target[int(0.9 * len(dataset_genotypes_target)):]\n",
    "\n",
    "# Pool\n",
    "phenotypes_target_idx_init = jax.random.choice(random_key, trainset_phenotypes_target.shape[0], shape=(config.exp.pool_size,), replace=True)\n",
    "cells_states_init = jax.vmap(init_cells_state)(phenotypes_target_idx_init)\n",
    "genotypes_target_init = jnp.take(trainset_genotypes_target, phenotypes_target_idx_init, axis=0)\n",
    "pool = Pool(cells_states=cells_states_init, phenotypes_target_idx=phenotypes_target_idx_init)\n",
    "\n",
    "# NCA\n",
    "nca = NCA(cell_state_size=cell_state_size, n_perceive_free=config.exp.n_perceive_free, update_size=config.exp.update_size, fire_rate=config.exp.fire_rate)\n",
    "random_key, random_subkey_1, random_subkey_2 = jax.random.split(random_key, 3)\n",
    "params = nca.init(random_subkey_1, random_subkey_2, cells_states_init[0], genotypes_target_init[0])\n",
    "params = nca.set_kernel(params)\n",
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "print(\"Number of parameters in NCA: \", param_count)\n",
    "\n",
    "# Train state\n",
    "lr_sched = optax.linear_schedule(init_value=config.exp.learning_rate, end_value=0.1*config.exp.learning_rate, transition_steps=2000)\n",
    "\n",
    "def zero_grads():\n",
    "    def init_fn(_):\n",
    "        return ()\n",
    "\n",
    "    def update_fn(updates, state, params=None):\n",
    "        return jax.jax.tree_util.tree_map(jnp.zeros_like, updates), ()\n",
    "    return optax.GradientTransformation(init_fn, update_fn)\n",
    "\n",
    "optimizer = optax.chain(\n",
    "    optax.clip_by_global_norm(1.0),\n",
    "    optax.adam(learning_rate=lr_sched),)\n",
    "tx = optax.multi_transform({False: optimizer, True: zero_grads()},\n",
    "                            nca.get_perceive_mask(params))\n",
    "\n",
    "train_state = TrainState.create(\n",
    "    apply_fn=nca.apply,\n",
    "    params=params,\n",
    "    tx=tx)\n",
    "\n",
    "# Train\n",
    "@jax.jit\n",
    "def loss_f(cell_states, phenotype):\n",
    "    return jnp.mean(jnp.square(to_rgba(cell_states) - phenotype), axis=(-1, -2, -3))\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "@jax.jit\n",
    "def scan_apply(carry, random_key):\n",
    "    (params, cells_states, genotype_target,) = carry\n",
    "    cells_states_ = train_state.apply_fn(params, random_key, cells_states, genotype_target)\n",
    "    return (params, cells_states_, genotype_target,), ()\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"n_iterations\",))\n",
    "def train_step(random_key, train_state, cells_states, genotype_target, phenotypes_target, n_iterations):\n",
    "    def loss_fn(params):\n",
    "        random_keys = jax.random.split(random_key, n_iterations)\n",
    "        (params, cells_states_, _,), _ = jax.lax.scan(scan_apply, (params, cells_states, genotype_target,), random_keys, length=n_iterations)\n",
    "        return loss_f(cells_states_, phenotypes_target).mean(), cells_states_\n",
    "\n",
    "    (loss, cells_states_), grads = jax.value_and_grad(loss_fn, has_aux=True)(train_state.params)\n",
    "    train_state = train_state.apply_gradients(grads=grads)\n",
    "\n",
    "    return train_state, loss, cells_states_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 16700\n",
    "params = load_params(params, run_path / \"nca_{:07d}.pickle\".format(i))\n",
    "\n",
    "train_state = TrainState.create(\n",
    "    apply_fn=nca.apply,\n",
    "    params=params,\n",
    "    tx=tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def scan_apply(carry, random_key):\n",
    "    (params, cells_states, genotype_target,) = carry\n",
    "    cells_states_ = train_state.apply_fn(params, random_key, cells_states, genotype_target)\n",
    "    return (params, cells_states_, genotype_target,), (cells_states_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 500\n",
    "phenotype_target_idx = 35\n",
    "\n",
    "cells_state = init_cells_state(None)\n",
    "phenotype_target = testset_phenotypes_target[phenotype_target_idx]\n",
    "genotype_target = testset_genotypes_target[phenotype_target_idx]\n",
    "\n",
    "random_keys = jax.random.split(random_key, n_iterations)\n",
    "(params, cells_state_, _,), (cells_states_,) = jax.lax.scan(\n",
    "    scan_apply,\n",
    "    (params, cells_state, genotype_target,),\n",
    "    random_keys,\n",
    "    length=n_iterations,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_states = jnp.concatenate([jnp.expand_dims(cells_state, axis=0), cells_states_], axis=0)\n",
    "imgs = jnp.concatenate([to_rgba(cells_states), jnp.repeat(to_rgba(phenotype_target)[None, ...], n_iterations+1, axis=0)], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [jnp2pil(to_rgb(img)) for img in imgs]\n",
    "imgs[0].save(run_path / \"{:06d}.gif\".format(phenotype_target_idx), save_all=True, append_images=imgs[1:], duration=100, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 500\n",
    "phenotype_target_idx = 36\n",
    "\n",
    "cells_state = init_cells_state(None)\n",
    "phenotype_target = testset_phenotypes_target[phenotype_target_idx]\n",
    "genotype_target = testset_genotypes_target[phenotype_target_idx]\n",
    "\n",
    "random_keys = jax.random.split(random_key, n_iterations)\n",
    "(params, cells_state_, _,), (cells_states_,) = jax.lax.scan(\n",
    "    scan_apply,\n",
    "    (params, cells_state, genotype_target,),\n",
    "    random_keys,\n",
    "    length=n_iterations,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
